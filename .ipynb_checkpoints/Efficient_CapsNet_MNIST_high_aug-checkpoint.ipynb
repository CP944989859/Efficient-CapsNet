{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Capsules Need is Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.120095Z",
     "start_time": "2020-12-28T17:22:00.008249Z"
    },
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1606507320391,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "id": "QkauzhWdH0wf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import math\n",
    "import cv2\n",
    "tf2 = tf.compat.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.161575Z",
     "start_time": "2020-12-28T17:22:01.126550Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.175375Z",
     "start_time": "2020-12-28T17:22:01.172511Z"
    }
   },
   "outputs": [],
   "source": [
    "# set some paths and config\n",
    "PATH_DIR = Path.cwd()\n",
    "name_model = 'efficient_capsnet_mnist'\n",
    "model_dir = PATH_DIR.joinpath('bin')\n",
    "media_dir = PATH_DIR.joinpath('media')\n",
    "log_dir = PATH_DIR.joinpath('logs')\n",
    "saved_model_name= model_dir.joinpath(f'{name_model}.h5')\n",
    "\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "ROUTING = False\n",
    "batch_size = 16\n",
    "MNIST_IMG_SIZE = 28\n",
    "MNIST_TRAIN_IMAGE_COUNT = 60000\n",
    "PARALLEL_INPUT_CALLS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHqF42VpH0wf"
   },
   "source": [
    "# Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.365375Z",
     "start_time": "2020-12-28T17:22:01.183006Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1606507412037,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "id": "edBtSa9DH0wf",
    "outputId": "21611749-b306-4e34-8e23-148a18f4584c"
   },
   "outputs": [],
   "source": [
    "# import the datatset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.377825Z",
     "start_time": "2020-12-28T17:22:01.374545Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize dataset\n",
    "def pre_process(x, y):\n",
    "    return (x / 256)[...,None].astype('float32'), tf.keras.utils.to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.514951Z",
     "start_time": "2020-12-28T17:22:01.387017Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1039,
     "status": "ok",
     "timestamp": 1606507412306,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "id": "RmKuQIk4H0wg",
    "outputId": "410db08f-709c-4dc8-d65b-dfb6a09c2569"
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X_train, y_train = pre_process(X_train, y_train)\n",
    "X_test, y_test = pre_process(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.537323Z",
     "start_time": "2020-12-28T17:22:01.529405Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_shift_rand(image, label):\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE, MNIST_IMG_SIZE])\n",
    "    nonzero_x_cols = tf.cast(tf.where(tf.greater(\n",
    "        tf.reduce_sum(image, axis=0), 0)), tf.int32)\n",
    "    nonzero_y_rows = tf.cast(tf.where(tf.greater(\n",
    "        tf.reduce_sum(image, axis=1), 0)), tf.int32)\n",
    "    left_margin = tf.reduce_min(nonzero_x_cols)\n",
    "    right_margin = MNIST_IMG_SIZE - tf.reduce_max(nonzero_x_cols) - 1\n",
    "    top_margin = tf.reduce_min(nonzero_y_rows)\n",
    "    bot_margin = MNIST_IMG_SIZE - tf.reduce_max(nonzero_y_rows) - 1\n",
    "    rand_dirs = tf.random.uniform([2])\n",
    "    dir_idxs = tf.cast(tf.floor(rand_dirs * 2), tf.int32)\n",
    "    rand_amts = tf.minimum(tf.abs(tf.random.normal([2], 0, .33)), .9999)\n",
    "    x_amts = [tf.floor(-1.0 * rand_amts[0] *\n",
    "              tf.cast(left_margin, tf.float32)), tf.floor(rand_amts[0] *\n",
    "              tf.cast(1 + right_margin, tf.float32))]\n",
    "    y_amts = [tf.floor(-1.0 * rand_amts[1] *\n",
    "              tf.cast(top_margin, tf.float32)), tf.floor(rand_amts[1] *\n",
    "              tf.cast(1 + bot_margin, tf.float32))]\n",
    "    x_amt = tf.cast(tf.gather(x_amts, dir_idxs[1], axis=0), tf.int32)\n",
    "    y_amt = tf.cast(tf.gather(y_amts, dir_idxs[0], axis=0), tf.int32)\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE * MNIST_IMG_SIZE])\n",
    "    image = tf.roll(image, y_amt * MNIST_IMG_SIZE, axis=0)\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE, MNIST_IMG_SIZE])\n",
    "    image = tf.transpose(image)\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE * MNIST_IMG_SIZE])\n",
    "    image = tf.roll(image, x_amt * MNIST_IMG_SIZE, axis=0)\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE, MNIST_IMG_SIZE])\n",
    "    image = tf.transpose(image)\n",
    "    image = tf.reshape(image, [MNIST_IMG_SIZE, MNIST_IMG_SIZE, 1])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.676586Z",
     "start_time": "2020-12-28T17:22:01.674648Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_center(image, label):\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:01.846714Z",
     "start_time": "2020-12-28T17:22:01.841498Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_squish_random(image, label):\n",
    "    rand_amts = tf.minimum(tf.abs(tf.random.normal([2], 0, .33)), .9999)\n",
    "    width_mod = tf.cast(tf.floor(\n",
    "        (rand_amts[0] * (MNIST_IMG_SIZE / 4)) + 1), tf.int32)\n",
    "    offset_mod = tf.cast(tf.floor(rand_amts[1] * 2.0), tf.int32)\n",
    "    offset = (width_mod // 2) + offset_mod\n",
    "    image = tf.image.resize(image,\n",
    "        [MNIST_IMG_SIZE, MNIST_IMG_SIZE - width_mod],\n",
    "        method=tf2.image.ResizeMethod.LANCZOS3,\n",
    "        preserve_aspect_ratio=False,\n",
    "        antialias=True)\n",
    "    image = tf.image.pad_to_bounding_box(\n",
    "        image, 0, offset, MNIST_IMG_SIZE, MNIST_IMG_SIZE + offset_mod)\n",
    "    image = tf.image.crop_to_bounding_box(\n",
    "        image, 0, 0, MNIST_IMG_SIZE, MNIST_IMG_SIZE)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:02.100559Z",
     "start_time": "2020-12-28T17:22:02.098357Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_rotate_random_py_func(image, angle):\n",
    "    rot_mat = cv2.getRotationMatrix2D(\n",
    "        (MNIST_IMG_SIZE/2, MNIST_IMG_SIZE/2), int(angle), 1.0)\n",
    "    rotated = cv2.warpAffine(image.numpy(), rot_mat,\n",
    "        (MNIST_IMG_SIZE, MNIST_IMG_SIZE))\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:02.416340Z",
     "start_time": "2020-12-28T17:22:02.413513Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_rotate_random(image, label):\n",
    "    rand_amts = tf.maximum(tf.minimum(\n",
    "        tf.random.normal([2], 0, .33), .9999), -.9999)\n",
    "    angle = rand_amts[0] * 30  # degrees\n",
    "    new_image = tf.py_function(image_rotate_random_py_func,\n",
    "        (image, angle), tf.float32)\n",
    "    new_image = tf.cond(rand_amts[1] > 0, lambda: image, lambda: new_image)\n",
    "    return new_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:02.496603Z",
     "start_time": "2020-12-28T17:22:02.493344Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_erase_random(image, label):\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        rand_amts = tf.random.uniform([2])\n",
    "        x = tf.cast(tf.floor(rand_amts[0]*19)+4, tf.int32)\n",
    "        y = tf.cast(tf.floor(rand_amts[1]*19)+4, tf.int32)\n",
    "        patch = tf.zeros([4, 4])\n",
    "        mask = tf.pad(patch, [[x, MNIST_IMG_SIZE-x-4],\n",
    "            [y, MNIST_IMG_SIZE-y-4]],\n",
    "            mode='CONSTANT', constant_values=1)\n",
    "        image = tf.multiply(image, tf.expand_dims(mask, -1))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:02.793916Z",
     "start_time": "2020-12-28T17:22:02.792001Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator(image, label):\n",
    "    return (image, label), (label, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:04.183448Z",
     "start_time": "2020-12-28T17:22:03.038293Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "dataset = dataset.shuffle(buffer_size=MNIST_TRAIN_IMAGE_COUNT)\n",
    "dataset = dataset.map(image_rotate_random)\n",
    "dataset = dataset.map(image_shift_rand,\n",
    "    num_parallel_calls=PARALLEL_INPUT_CALLS)\n",
    "dataset = dataset.map(image_squish_random,\n",
    "    num_parallel_calls=PARALLEL_INPUT_CALLS)\n",
    "dataset = dataset.map(image_erase_random,\n",
    "   num_parallel_calls=PARALLEL_INPUT_CALLS)\n",
    "dataset = dataset.map(generator, num_parallel_calls=PARALLEL_INPUT_CALLS)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:04.216106Z",
     "start_time": "2020-12-28T17:22:04.199708Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_val = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "dataset_val = dataset_val.cache()\n",
    "dataset_val = dataset_val.map(generator,\n",
    "    num_parallel_calls=PARALLEL_INPUT_CALLS)\n",
    "dataset_val = dataset_val.batch(batch_size)\n",
    "dataset_val = dataset_val.prefetch(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWHZ-D9nH0wg"
   },
   "source": [
    "# CapsNet Classes and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:04.233841Z",
     "start_time": "2020-12-28T17:22:04.231113Z"
    },
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1606507412887,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "id": "CMeLu_sEH0wg"
   },
   "outputs": [],
   "source": [
    "def squash_hinton(s):\n",
    "    n = tf.norm(s,axis=-1,keepdims=True)\n",
    "    return tf.multiply(n**2/(1+n**2)/(n+10e-14),s)\n",
    "\n",
    "def squash(s):\n",
    "    n = tf.norm(s,axis=-1,keepdims=True)\n",
    "    return (1 - 1/(tf.math.exp(n)+10e-21))*(s/(n+10e-21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:04.306068Z",
     "start_time": "2020-12-28T17:22:04.304072Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_orientation(x):\n",
    "    return np.arctan2(x[1],x[0]) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:04.732506Z",
     "start_time": "2020-12-28T17:22:04.729824Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(x, y, batch_size, shift_fraction=0., generator_net=False):\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                       height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "    generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "    while True:\n",
    "        X_batch, y_batch = generator.next()\n",
    "        if generator_net:\n",
    "            yield (X_batch, y_batch), (y_batch, X_batch)\n",
    "        else:\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:05.247520Z",
     "start_time": "2020-12-28T17:22:05.239129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orientation 2D vector before:  126.86989764584402\n",
      "Orientation 2D vector squash Hinton:  126.86989764584402\n",
      "Orientation 2D vector squash:  126.86989764584402\n"
     ]
    }
   ],
   "source": [
    "v = np.array([-3.,4.])\n",
    "print(\"Orientation 2D vector before: \", compute_orientation(v))\n",
    "print(\"Orientation 2D vector squash Hinton: \", compute_orientation(squash_hinton(v)))\n",
    "print(\"Orientation 2D vector squash: \", compute_orientation(squash(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:05.872343Z",
     "start_time": "2020-12-28T17:22:05.868639Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrimaryCaps(tf.keras.layers.Layer):\n",
    "    def __init__(self, F, k, C, L, **kwargs):\n",
    "        super(PrimaryCaps, self).__init__(**kwargs)\n",
    "        self.F = F\n",
    "        self.k = k\n",
    "        self.C = C\n",
    "        self.L = L\n",
    "        \n",
    "    def build(self, input_shape):    \n",
    "        self.Conv2D = tf.keras.layers.Conv2D(self.F, self.k,\n",
    "                                             activation='relu', groups=self.F, padding='valid')\n",
    "\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.Conv2D(inputs)\n",
    "        \n",
    "        \n",
    "        x = tf.keras.layers.Reshape((self.C, self.L))(x)\n",
    "        x = tf.keras.layers.Lambda(squash, name='squash')(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:06.782132Z",
     "start_time": "2020-12-28T17:22:06.779925Z"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1606507560755,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "id": "tQpBX-4-H0wh"
   },
   "outputs": [],
   "source": [
    "# class DigitCaps(tf.keras.layers.Layer):\n",
    "#     def __init__(self,C,L,routing=None,kernel_initializer='glorot_uniform',**kwargs):\n",
    "#         super(DigitCaps, self).__init__(**kwargs)\n",
    "#         self.C = C\n",
    "#         self.L = L\n",
    "#         self.routing = routing\n",
    "#         self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        \n",
    "#     def build(self, input_shape):\n",
    "#         input_C = input_shape[-2]\n",
    "#         input_L = input_shape[-1]\n",
    "\n",
    "#         self.W = self.add_weight(shape=[self.C,input_C,input_L,self.L],initializer=self.kernel_initializer,name='W')\n",
    "#         self.built = True\n",
    "    \n",
    "#     def call(self, inputs, training=None):\n",
    "        \n",
    "#         u = tf.einsum('...ji,kjiz->...kjz',inputs,self.W)    # u shape=(None,C,H*W*input_C,L)\n",
    "        \n",
    "#         if self.routing is not None: #Hinton's routing\n",
    "#             b = tf.zeros(tf.shape(u)[:-1])[...,None]                        # b shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "#             assert self.routing > 0, 'The routings should be > 0.'\n",
    "#             for r in range(self.routing):\n",
    "#                 c = tf.nn.softmax(b,axis=1)                                # c shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "#                 s = tf.reduce_sum(tf.multiply(u,c),axis=-2,keepdims=True)  # s shape=(None,C,1,L)\n",
    "#                 v = squash(s)\n",
    "#                 if r<self.routing:\n",
    "#                     b += tf.reduce_sum(tf.multiply(u,v),axis=-1,keepdims=True)\n",
    "#             v = v[...,0,:]      # v shape=(None,C,L)\n",
    "#         else: #ours routing\n",
    "#             b = tf.einsum('...ij,...kj->...i',u,u)[...,None]        # b shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "#             b = b/tf.sqrt(tf.cast(self.L, tf.float32))\n",
    "#             c = tf.nn.softmax(b,axis=1)                             # c shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "#             s = tf.reduce_sum(tf.multiply(u,c),axis=-2)             # s shape=(None,C,L)\n",
    "#             v = squash(s)       # v shape=(None,C,L)\n",
    "#         return v\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (None, self.C, self.L)\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = {\n",
    "#             'C': self.C,\n",
    "#             'L': self.L,\n",
    "#             'routing': self.routing\n",
    "#         }\n",
    "#         base_config = super(DigitCaps, self).get_config()\n",
    "#         return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:07.483497Z",
     "start_time": "2020-12-28T17:22:07.475717Z"
    }
   },
   "outputs": [],
   "source": [
    "class DigitCaps(tf.keras.layers.Layer):\n",
    "    def __init__(self,C,L,routing=None,kernel_initializer='he_normal',**kwargs):\n",
    "        super(DigitCaps, self).__init__(**kwargs)\n",
    "        self.C = C\n",
    "        self.L = L\n",
    "        self.routing = routing\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_C = input_shape[-2]\n",
    "        input_L = input_shape[-1]\n",
    "\n",
    "        self.W = self.add_weight(shape=[self.C,input_C,input_L,self.L],initializer=self.kernel_initializer,name='W')\n",
    "        self.b = self.add_weight(shape=[self.C,input_C,1], initializer=tf.zeros_initializer(), name='b')\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        \n",
    "        u = tf.einsum('...ji,kjiz->...kjz',inputs,self.W)    # u shape=(None,C,H*W*input_C,L)\n",
    "        \n",
    "        if self.routing is not None: #Hinton's routing\n",
    "            \n",
    "            c = tf.identity(self.b)       # b shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "            assert self.routing > 0, 'The routings should be > 0.'\n",
    "            for r in range(self.routing):\n",
    "                c = tf.nn.softmax(c,axis=1)                                # c shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "                s = tf.reduce_sum(tf.multiply(u,c),axis=-2,keepdims=True)  # s shape=(None,C,1,L)\n",
    "                v = squash(s)\n",
    "                if r<self.routing:\n",
    "                    c += tf.reduce_sum(tf.multiply(u,v),axis=-1,keepdims=True)\n",
    "            v = v[...,0,:]      # v shape=(None,C,L)\n",
    "        else: #ours routing\n",
    "            c = tf.einsum('...ij,...kj->...i',u,u)[...,None]        # b shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "            c = c/tf.sqrt(tf.cast(self.L, tf.float32))\n",
    "            c = tf.nn.softmax(c,axis=1)                             # c shape=(None,C,H*W*input_C,1) -> (None,j,i,1)\n",
    "            c = c + self.b\n",
    "            s = tf.reduce_sum(tf.multiply(u,c),axis=-2)             # s shape=(None,C,L)\n",
    "            v = squash(s)       # v shape=(None,C,L)\n",
    "        return v\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.C, self.L)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'C': self.C,\n",
    "            'L': self.L,\n",
    "            'routing': self.routing\n",
    "        }\n",
    "        base_config = super(DigitCaps, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:07.994194Z",
     "start_time": "2020-12-28T17:22:07.991208Z"
    }
   },
   "outputs": [],
   "source": [
    "class Length(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
    "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
    "    inputs: shape=[None, num_vectors, dim_vector]\n",
    "    output: shape=[None, num_vectors]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + tf.keras.backend.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:08.531380Z",
     "start_time": "2020-12-28T17:22:08.527210Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images, height=None, width=None):\n",
    "    num = generated_images.shape[0]\n",
    "    if width is None and height is None:\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif width is not None and height is None:  # height not given\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif height is not None and width is None:  # width not given\n",
    "        width = int(math.ceil(float(num)/height))\n",
    "\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:09.138656Z",
     "start_time": "2020-12-28T17:22:09.132722Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mask(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
    "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
    "    masked Tensor.\n",
    "    For example:\n",
    "        ```\n",
    "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
    "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
    "        out = Mask()(x)  # out.shape=[8, 6]\n",
    "        # or\n",
    "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = tf.keras.backend.one_hot(indices=tf.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:10.144125Z",
     "start_time": "2020-12-28T17:22:10.141582Z"
    }
   },
   "outputs": [],
   "source": [
    "def marginLoss(y_true, y_pred):\n",
    "    \n",
    "    lbd = 0.5\n",
    "    m_plus = 0.9\n",
    "    m_minus = 0.1\n",
    "    \n",
    "    L = y_true * tf.square(tf.maximum(0., m_plus - y_pred)) + \\\n",
    "    lbd * (1 - y_true) * tf.square(tf.maximum(0., y_pred - m_minus))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CapsNet without Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T11:54:00.372812Z",
     "start_time": "2020-12-28T11:54:00.368846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def CapsNet():\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32,5,activation=\"relu\", padding='valid')(inputs)\n",
    "    x = tf.keras.layers.Conv2D(64,3, activation='relu', padding='valid')(x)\n",
    "    x = tf.keras.layers.Conv2D(64,3, activation='relu', padding='valid')(x)\n",
    "    x = tf.keras.layers.Conv2D(128,3,2, activation='relu', padding='valid')(x)   \n",
    "    #x = PrimaryCaps(F=256, k=10, C=32, L=8)(x)\n",
    "    x = tf.keras.layers.Conv2D(128, 9, activation='linear', groups=128, padding='valid')(x)\n",
    "    x = tf.keras.layers.Reshape((16,8))(x)\n",
    "    x = DigitCaps(10,16)(x)\n",
    "    \n",
    "    x = Length(name='micro_capsnet_output')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs,outputs=x, name='CapsNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:15:40.245700Z",
     "start_time": "2020-12-26T15:15:40.071214Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1606507574670,
     "user": {
      "displayName": "Francesco Salvetti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh51hhSjGpYBdTUoBi9QzXQ_ZQ71SITK1bwMzjV=s64",
      "userId": "12996531273344737864"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "wDa18cokH0wh",
    "outputId": "a6d9f574-097d-4373-f435-d305fd686f2b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CapsNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "vJ4RXPltIR9Q"
   },
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:15:41.308202Z",
     "start_time": "2020-12-26T15:15:41.303133Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lr_dec = 0.96\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "shift_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:15:42.004039Z",
     "start_time": "2020-12-26T15:15:41.992991Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(\n",
    "    loss=marginLoss,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(saved_model_name, monitor='val_accuracy',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "lr_decay = tf.keras.callbacks.LearningRateScheduler(schedule=lambda epoch: lr * (lr_dec ** epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:15:44.887668Z",
     "start_time": "2020-12-26T15:15:42.447837Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "history = model.fit(train_generator(X_train, y_train, batch_size, shift_fraction),\n",
    "                    steps_per_epoch=int(y_train.shape[0] / batch_size),\n",
    "                    epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),\n",
    "                   callbacks=[lr_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(saved_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-'*30 + 'MNIST test set' + '-'*30)\n",
    "scores = model.evaluate(X_test,y_test)\n",
    "print(f\"Test loss: {scores[0]}\")\n",
    "print(f\"Test accuracy: {scores[1]}\")\n",
    "print(f\"Test error %: {(1 - scores[1])*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**MNIST Preliminary Tests without Generator**\n",
    "- CapsNet Dynamic Routing (no augmentation): Acc = 0.990\n",
    "- CapsNet Self-Attention (no augmentation): Acc = 0.991\n",
    "\n",
    "**MNIST Tests with Generator**\n",
    "- CapsNet Dynamic Routing (augmentation): Test % = 0.480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapsNet with Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:22:12.586246Z",
     "start_time": "2020-12-28T17:22:12.583127Z"
    }
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.Input(16*10)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(512, activation='relu', kernel_initializer='he_normal')(inputs)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.Dense(np.prod(input_shape), activation='sigmoid', kernel_initializer='glorot_normal')(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=input_shape, name='out_generator')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:20.646403Z",
     "start_time": "2020-12-28T17:23:20.641179Z"
    }
   },
   "outputs": [],
   "source": [
    "def CapsNet():\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32,5,activation=\"relu\", padding='valid', kernel_initializer='he_normal')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64,3, activation='relu', padding='valid', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64,3, activation='relu', padding='valid', kernel_initializer='he_normal')(x)   \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128,3,2, activation='relu', padding='valid', kernel_initializer='he_normal')(x)   \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, 9, activation='linear', groups=128, padding='valid')(x)\n",
    "    x = tf.keras.layers.Reshape((16,8))(x)\n",
    "    x = tf.keras.layers.Lambda(squash, name='squash')(x)\n",
    "    digit_caps = DigitCaps(10,16)(x)\n",
    "    \n",
    "    digit_caps_len = Length(name='micro_capsnet_output')(digit_caps)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs,outputs=[digit_caps,digit_caps_len], name='CapsNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:21.417395Z",
     "start_time": "2020-12-28T17:23:21.414547Z"
    }
   },
   "outputs": [],
   "source": [
    "def Model(generator):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    y_true = tf.keras.layers.Input(shape=(10,))\n",
    "    \n",
    "    digit_caps, digit_caps_len = CapsNet()(inputs)\n",
    "    \n",
    "    masked_by_y = Mask()([digit_caps, y_true])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digit_caps)  # Mask using the capsule with maximal length. For prediction\n",
    "    \n",
    "    x_rec_train = generator(masked_by_y)\n",
    "    x_rec_eval = generator(masked)\n",
    "    \n",
    "    return tf.keras.models.Model([inputs, y_true], [digit_caps_len, x_rec_train]), tf.keras.models.Model([inputs, y_true], [digit_caps_len, x_rec_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:22.095954Z",
     "start_time": "2020-12-28T17:23:21.801943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CapsNet (Functional)            [(None, 10, 16), (No 162400      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_2 (Mask)                   (None, 160)          0           CapsNet[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Generator (Functional)          (None, 28, 28, 1)    1411344     mask_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,573,744\n",
      "Trainable params: 1,573,168\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train, model_eval = Model(Generator())\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:24.942868Z",
     "start_time": "2020-12-28T17:23:24.940688Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_lr(fn):\n",
    "    y = []\n",
    "    for epoch in range(epochs):\n",
    "        y.append(fn(epoch))\n",
    "        \n",
    "    plt.plot(range(epochs), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:25.479577Z",
     "start_time": "2020-12-28T17:23:25.477511Z"
    }
   },
   "outputs": [],
   "source": [
    "def learning_scheduler_fn(epoch):\n",
    "    lr_new = lr * (lr_dec ** epoch)\n",
    "    return lr_new if lr_new >= 5e-5 else 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:26.050740Z",
     "start_time": "2020-12-28T17:23:26.048747Z"
    }
   },
   "outputs": [],
   "source": [
    "#decay_steps=2000\n",
    "lr = 5e-4\n",
    "lr_dec = 0.98\n",
    "epochs = 100\n",
    "lam_recon = 0.392\n",
    "version = '_v0'\n",
    "log_save_dir = log_dir.joinpath(name_model + '_' + version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:26.968412Z",
     "start_time": "2020-12-28T17:23:26.892102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if log_save_dir.is_dir():\n",
    "    shutil.rmtree(log_save_dir)\n",
    "print_lr(learning_scheduler_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:23:27.638503Z",
     "start_time": "2020-12-28T17:23:27.569304Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_train.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=[marginLoss, 'mse'],\n",
    "              loss_weights=[1., lam_recon],\n",
    "              metrics={'CapsNet': 'accuracy'})\n",
    "\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_save_dir, histogram_freq=0)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(saved_model_name, monitor='val_CapsNet_accuracy',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "lr_decay = tf.keras.callbacks.LearningRateScheduler(learning_scheduler_fn)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_CapsNet_accuracy', factor=0.9,\n",
    "                              patience=4, min_lr=0.00001, min_delta=0.0001, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:40:38.642316Z",
     "start_time": "2020-12-28T17:23:28.096135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/3750 [..............................] - ETA: 0s - loss: 0.8678 - CapsNet_loss: 0.7791 - Generator_loss: 0.2262 - CapsNet_accuracy: 0.0000e+00WARNING:tensorflow:From /home/vitto/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_train_batch_end` time: 0.0297s). Check your callbacks.\n",
      "3744/3750 [============================>.] - ETA: 0s - loss: 0.1125 - CapsNet_loss: 0.0892 - Generator_loss: 0.0593 - CapsNet_accuracy: 0.9085\n",
      "Epoch 00001: val_CapsNet_accuracy improved from -inf to 0.98530, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 31s 8ms/step - loss: 0.1124 - CapsNet_loss: 0.0891 - Generator_loss: 0.0593 - CapsNet_accuracy: 0.9085 - val_loss: 0.0370 - val_CapsNet_loss: 0.0139 - val_Generator_loss: 0.0590 - val_CapsNet_accuracy: 0.9853\n",
      "Epoch 2/100\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0534 - CapsNet_loss: 0.0320 - Generator_loss: 0.0547 - CapsNet_accuracy: 0.9626\n",
      "Epoch 00002: val_CapsNet_accuracy did not improve from 0.98530\n",
      "3750/3750 [==============================] - 31s 8ms/step - loss: 0.0534 - CapsNet_loss: 0.0320 - Generator_loss: 0.0547 - CapsNet_accuracy: 0.9625 - val_loss: 0.0406 - val_CapsNet_loss: 0.0192 - val_Generator_loss: 0.0545 - val_CapsNet_accuracy: 0.9804\n",
      "Epoch 3/100\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0448 - CapsNet_loss: 0.0257 - Generator_loss: 0.0487 - CapsNet_accuracy: 0.9708\n",
      "Epoch 00003: val_CapsNet_accuracy did not improve from 0.98530\n",
      "3750/3750 [==============================] - 32s 8ms/step - loss: 0.0448 - CapsNet_loss: 0.0257 - Generator_loss: 0.0487 - CapsNet_accuracy: 0.9707 - val_loss: 0.0341 - val_CapsNet_loss: 0.0156 - val_Generator_loss: 0.0471 - val_CapsNet_accuracy: 0.9822\n",
      "Epoch 4/100\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0383 - CapsNet_loss: 0.0218 - Generator_loss: 0.0421 - CapsNet_accuracy: 0.9755\n",
      "Epoch 00004: val_CapsNet_accuracy improved from 0.98530 to 0.99010, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 31s 8ms/step - loss: 0.0383 - CapsNet_loss: 0.0218 - Generator_loss: 0.0421 - CapsNet_accuracy: 0.9756 - val_loss: 0.0268 - val_CapsNet_loss: 0.0104 - val_Generator_loss: 0.0420 - val_CapsNet_accuracy: 0.9901\n",
      "Epoch 5/100\n",
      "3739/3750 [============================>.] - ETA: 0s - loss: 0.0344 - CapsNet_loss: 0.0196 - Generator_loss: 0.0378 - CapsNet_accuracy: 0.9788\n",
      "Epoch 00005: val_CapsNet_accuracy improved from 0.99010 to 0.99260, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 0.0344 - CapsNet_loss: 0.0196 - Generator_loss: 0.0378 - CapsNet_accuracy: 0.9788 - val_loss: 0.0217 - val_CapsNet_loss: 0.0074 - val_Generator_loss: 0.0365 - val_CapsNet_accuracy: 0.9926\n",
      "Epoch 6/100\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.0315 - CapsNet_loss: 0.0179 - Generator_loss: 0.0348 - CapsNet_accuracy: 0.9805\n",
      "Epoch 00006: val_CapsNet_accuracy improved from 0.99260 to 0.99290, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 29s 8ms/step - loss: 0.0315 - CapsNet_loss: 0.0179 - Generator_loss: 0.0348 - CapsNet_accuracy: 0.9805 - val_loss: 0.0205 - val_CapsNet_loss: 0.0074 - val_Generator_loss: 0.0334 - val_CapsNet_accuracy: 0.9929\n",
      "Epoch 7/100\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0296 - CapsNet_loss: 0.0169 - Generator_loss: 0.0325 - CapsNet_accuracy: 0.9812\n",
      "Epoch 00007: val_CapsNet_accuracy did not improve from 0.99290\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0296 - CapsNet_loss: 0.0169 - Generator_loss: 0.0325 - CapsNet_accuracy: 0.9811 - val_loss: 0.0193 - val_CapsNet_loss: 0.0070 - val_Generator_loss: 0.0312 - val_CapsNet_accuracy: 0.9928\n",
      "Epoch 8/100\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0280 - CapsNet_loss: 0.0158 - Generator_loss: 0.0310 - CapsNet_accuracy: 0.9829\n",
      "Epoch 00008: val_CapsNet_accuracy did not improve from 0.99290\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0280 - CapsNet_loss: 0.0158 - Generator_loss: 0.0310 - CapsNet_accuracy: 0.9829 - val_loss: 0.0191 - val_CapsNet_loss: 0.0072 - val_Generator_loss: 0.0304 - val_CapsNet_accuracy: 0.9922\n",
      "Epoch 9/100\n",
      "3744/3750 [============================>.] - ETA: 0s - loss: 0.0263 - CapsNet_loss: 0.0147 - Generator_loss: 0.0296 - CapsNet_accuracy: 0.9838\n",
      "Epoch 00009: val_CapsNet_accuracy improved from 0.99290 to 0.99510, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0263 - CapsNet_loss: 0.0147 - Generator_loss: 0.0296 - CapsNet_accuracy: 0.9838 - val_loss: 0.0166 - val_CapsNet_loss: 0.0055 - val_Generator_loss: 0.0284 - val_CapsNet_accuracy: 0.9951\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.0254 - CapsNet_loss: 0.0142 - Generator_loss: 0.0285 - CapsNet_accuracy: 0.9844\n",
      "Epoch 00010: val_CapsNet_accuracy did not improve from 0.99510\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0254 - CapsNet_loss: 0.0142 - Generator_loss: 0.0285 - CapsNet_accuracy: 0.9844 - val_loss: 0.0160 - val_CapsNet_loss: 0.0054 - val_Generator_loss: 0.0271 - val_CapsNet_accuracy: 0.9939\n",
      "Epoch 11/100\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0243 - CapsNet_loss: 0.0135 - Generator_loss: 0.0275 - CapsNet_accuracy: 0.9853\n",
      "Epoch 00011: val_CapsNet_accuracy did not improve from 0.99510\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0242 - CapsNet_loss: 0.0135 - Generator_loss: 0.0275 - CapsNet_accuracy: 0.9853 - val_loss: 0.0164 - val_CapsNet_loss: 0.0061 - val_Generator_loss: 0.0263 - val_CapsNet_accuracy: 0.9937\n",
      "Epoch 12/100\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0234 - CapsNet_loss: 0.0130 - Generator_loss: 0.0267 - CapsNet_accuracy: 0.9862\n",
      "Epoch 00012: val_CapsNet_accuracy did not improve from 0.99510\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0234 - CapsNet_loss: 0.0130 - Generator_loss: 0.0267 - CapsNet_accuracy: 0.9862 - val_loss: 0.0149 - val_CapsNet_loss: 0.0051 - val_Generator_loss: 0.0250 - val_CapsNet_accuracy: 0.9949\n",
      "Epoch 13/100\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0224 - CapsNet_loss: 0.0123 - Generator_loss: 0.0258 - CapsNet_accuracy: 0.9870\n",
      "Epoch 00013: val_CapsNet_accuracy did not improve from 0.99510\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0224 - CapsNet_loss: 0.0123 - Generator_loss: 0.0258 - CapsNet_accuracy: 0.9870 - val_loss: 0.0159 - val_CapsNet_loss: 0.0063 - val_Generator_loss: 0.0246 - val_CapsNet_accuracy: 0.9934\n",
      "Epoch 14/100\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0221 - CapsNet_loss: 0.0122 - Generator_loss: 0.0251 - CapsNet_accuracy: 0.9875\n",
      "Epoch 00014: val_CapsNet_accuracy improved from 0.99510 to 0.99520, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0221 - CapsNet_loss: 0.0123 - Generator_loss: 0.0251 - CapsNet_accuracy: 0.9875 - val_loss: 0.0143 - val_CapsNet_loss: 0.0052 - val_Generator_loss: 0.0233 - val_CapsNet_accuracy: 0.9952\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.0210 - CapsNet_loss: 0.0114 - Generator_loss: 0.0245 - CapsNet_accuracy: 0.9878\n",
      "Epoch 00015: val_CapsNet_accuracy did not improve from 0.99520\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0210 - CapsNet_loss: 0.0114 - Generator_loss: 0.0245 - CapsNet_accuracy: 0.9878 - val_loss: 0.0148 - val_CapsNet_loss: 0.0058 - val_Generator_loss: 0.0229 - val_CapsNet_accuracy: 0.9943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "3742/3750 [============================>.] - ETA: 0s - loss: 0.0208 - CapsNet_loss: 0.0114 - Generator_loss: 0.0240 - CapsNet_accuracy: 0.9877\n",
      "Epoch 00016: val_CapsNet_accuracy did not improve from 0.99520\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0208 - CapsNet_loss: 0.0114 - Generator_loss: 0.0240 - CapsNet_accuracy: 0.9877 - val_loss: 0.0145 - val_CapsNet_loss: 0.0056 - val_Generator_loss: 0.0226 - val_CapsNet_accuracy: 0.9943\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.0203 - CapsNet_loss: 0.0111 - Generator_loss: 0.0236 - CapsNet_accuracy: 0.9882\n",
      "Epoch 00017: val_CapsNet_accuracy did not improve from 0.99520\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0203 - CapsNet_loss: 0.0111 - Generator_loss: 0.0236 - CapsNet_accuracy: 0.9882 - val_loss: 0.0141 - val_CapsNet_loss: 0.0055 - val_Generator_loss: 0.0220 - val_CapsNet_accuracy: 0.9950\n",
      "Epoch 18/100\n",
      "3743/3750 [============================>.] - ETA: 0s - loss: 0.0197 - CapsNet_loss: 0.0107 - Generator_loss: 0.0230 - CapsNet_accuracy: 0.9882\n",
      "Epoch 00018: val_CapsNet_accuracy improved from 0.99520 to 0.99530, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0197 - CapsNet_loss: 0.0107 - Generator_loss: 0.0230 - CapsNet_accuracy: 0.9882 - val_loss: 0.0128 - val_CapsNet_loss: 0.0044 - val_Generator_loss: 0.0212 - val_CapsNet_accuracy: 0.9953\n",
      "Epoch 19/100\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0191 - CapsNet_loss: 0.0102 - Generator_loss: 0.0227 - CapsNet_accuracy: 0.9893\n",
      "Epoch 00019: val_CapsNet_accuracy improved from 0.99530 to 0.99580, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0191 - CapsNet_loss: 0.0102 - Generator_loss: 0.0227 - CapsNet_accuracy: 0.9894 - val_loss: 0.0127 - val_CapsNet_loss: 0.0046 - val_Generator_loss: 0.0206 - val_CapsNet_accuracy: 0.9958\n",
      "Epoch 20/100\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0185 - CapsNet_loss: 0.0098 - Generator_loss: 0.0223 - CapsNet_accuracy: 0.9896\n",
      "Epoch 00020: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0185 - CapsNet_loss: 0.0098 - Generator_loss: 0.0223 - CapsNet_accuracy: 0.9896 - val_loss: 0.0145 - val_CapsNet_loss: 0.0063 - val_Generator_loss: 0.0207 - val_CapsNet_accuracy: 0.9939\n",
      "Epoch 21/100\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.0185 - CapsNet_loss: 0.0099 - Generator_loss: 0.0219 - CapsNet_accuracy: 0.9895\n",
      "Epoch 00021: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0185 - CapsNet_loss: 0.0099 - Generator_loss: 0.0219 - CapsNet_accuracy: 0.9895 - val_loss: 0.0121 - val_CapsNet_loss: 0.0043 - val_Generator_loss: 0.0199 - val_CapsNet_accuracy: 0.9958\n",
      "Epoch 22/100\n",
      "3742/3750 [============================>.] - ETA: 0s - loss: 0.0181 - CapsNet_loss: 0.0097 - Generator_loss: 0.0216 - CapsNet_accuracy: 0.9899\n",
      "Epoch 00022: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0181 - CapsNet_loss: 0.0097 - Generator_loss: 0.0216 - CapsNet_accuracy: 0.9899 - val_loss: 0.0121 - val_CapsNet_loss: 0.0045 - val_Generator_loss: 0.0195 - val_CapsNet_accuracy: 0.9951\n",
      "Epoch 23/100\n",
      "3743/3750 [============================>.] - ETA: 0s - loss: 0.0178 - CapsNet_loss: 0.0095 - Generator_loss: 0.0213 - CapsNet_accuracy: 0.9900\n",
      "Epoch 00023: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0178 - CapsNet_loss: 0.0095 - Generator_loss: 0.0213 - CapsNet_accuracy: 0.9901 - val_loss: 0.0117 - val_CapsNet_loss: 0.0042 - val_Generator_loss: 0.0193 - val_CapsNet_accuracy: 0.9958\n",
      "Epoch 24/100\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0178 - CapsNet_loss: 0.0096 - Generator_loss: 0.0210 - CapsNet_accuracy: 0.9901\n",
      "Epoch 00024: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0178 - CapsNet_loss: 0.0096 - Generator_loss: 0.0210 - CapsNet_accuracy: 0.9901 - val_loss: 0.0119 - val_CapsNet_loss: 0.0043 - val_Generator_loss: 0.0194 - val_CapsNet_accuracy: 0.9950\n",
      "Epoch 25/100\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0170 - CapsNet_loss: 0.0089 - Generator_loss: 0.0207 - CapsNet_accuracy: 0.9909\n",
      "Epoch 00025: val_CapsNet_accuracy did not improve from 0.99580\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0170 - CapsNet_loss: 0.0089 - Generator_loss: 0.0207 - CapsNet_accuracy: 0.9909 - val_loss: 0.0118 - val_CapsNet_loss: 0.0045 - val_Generator_loss: 0.0188 - val_CapsNet_accuracy: 0.9956\n",
      "Epoch 26/100\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0170 - CapsNet_loss: 0.0089 - Generator_loss: 0.0205 - CapsNet_accuracy: 0.9906\n",
      "Epoch 00026: val_CapsNet_accuracy improved from 0.99580 to 0.99600, saving model to /home/vitto/Documents/HyperCapsuleNet/bin/efficient_capsnet_mnist.h5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0170 - CapsNet_loss: 0.0089 - Generator_loss: 0.0205 - CapsNet_accuracy: 0.9906 - val_loss: 0.0114 - val_CapsNet_loss: 0.0042 - val_Generator_loss: 0.0183 - val_CapsNet_accuracy: 0.9960\n",
      "Epoch 27/100\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.0169 - CapsNet_loss: 0.0089 - Generator_loss: 0.0203 - CapsNet_accuracy: 0.9902\n",
      "Epoch 00027: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0169 - CapsNet_loss: 0.0089 - Generator_loss: 0.0203 - CapsNet_accuracy: 0.9902 - val_loss: 0.0130 - val_CapsNet_loss: 0.0057 - val_Generator_loss: 0.0186 - val_CapsNet_accuracy: 0.9944\n",
      "Epoch 28/100\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0164 - CapsNet_loss: 0.0085 - Generator_loss: 0.0200 - CapsNet_accuracy: 0.9913\n",
      "Epoch 00028: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0164 - CapsNet_loss: 0.0085 - Generator_loss: 0.0200 - CapsNet_accuracy: 0.9913 - val_loss: 0.0124 - val_CapsNet_loss: 0.0053 - val_Generator_loss: 0.0182 - val_CapsNet_accuracy: 0.9947\n",
      "Epoch 29/100\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.0162 - CapsNet_loss: 0.0085 - Generator_loss: 0.0198 - CapsNet_accuracy: 0.9912\n",
      "Epoch 00029: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0162 - CapsNet_loss: 0.0085 - Generator_loss: 0.0198 - CapsNet_accuracy: 0.9912 - val_loss: 0.0121 - val_CapsNet_loss: 0.0051 - val_Generator_loss: 0.0179 - val_CapsNet_accuracy: 0.9947\n",
      "Epoch 30/100\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.0160 - CapsNet_loss: 0.0083 - Generator_loss: 0.0196 - CapsNet_accuracy: 0.9913\n",
      "Epoch 00030: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0160 - CapsNet_loss: 0.0083 - Generator_loss: 0.0196 - CapsNet_accuracy: 0.9913 - val_loss: 0.0122 - val_CapsNet_loss: 0.0050 - val_Generator_loss: 0.0182 - val_CapsNet_accuracy: 0.9948\n",
      "Epoch 31/100\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0157 - CapsNet_loss: 0.0081 - Generator_loss: 0.0194 - CapsNet_accuracy: 0.9915\n",
      "Epoch 00031: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0157 - CapsNet_loss: 0.0081 - Generator_loss: 0.0194 - CapsNet_accuracy: 0.9915 - val_loss: 0.0113 - val_CapsNet_loss: 0.0043 - val_Generator_loss: 0.0177 - val_CapsNet_accuracy: 0.9956\n",
      "Epoch 32/100\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0156 - CapsNet_loss: 0.0081 - Generator_loss: 0.0192 - CapsNet_accuracy: 0.9916\n",
      "Epoch 00032: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0156 - CapsNet_loss: 0.0081 - Generator_loss: 0.0192 - CapsNet_accuracy: 0.9916 - val_loss: 0.0106 - val_CapsNet_loss: 0.0039 - val_Generator_loss: 0.0172 - val_CapsNet_accuracy: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "3743/3750 [============================>.] - ETA: 0s - loss: 0.0153 - CapsNet_loss: 0.0078 - Generator_loss: 0.0191 - CapsNet_accuracy: 0.9919\n",
      "Epoch 00033: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0153 - CapsNet_loss: 0.0078 - Generator_loss: 0.0191 - CapsNet_accuracy: 0.9919 - val_loss: 0.0108 - val_CapsNet_loss: 0.0041 - val_Generator_loss: 0.0170 - val_CapsNet_accuracy: 0.9955\n",
      "Epoch 34/100\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0154 - CapsNet_loss: 0.0080 - Generator_loss: 0.0189 - CapsNet_accuracy: 0.9913\n",
      "Epoch 00034: val_CapsNet_accuracy did not improve from 0.99600\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 0.0154 - CapsNet_loss: 0.0080 - Generator_loss: 0.0189 - CapsNet_accuracy: 0.9913 - val_loss: 0.0106 - val_CapsNet_loss: 0.0040 - val_Generator_loss: 0.0170 - val_CapsNet_accuracy: 0.9955\n",
      "Epoch 35/100\n",
      " 446/3750 [==>...........................] - ETA: 24s - loss: 0.0147 - CapsNet_loss: 0.0073 - Generator_loss: 0.0187 - CapsNet_accuracy: 0.9931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-4c9fa7d7ce23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           callbacks=[checkpoint, lr_decay, tb])\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/TensorFlow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_train.fit(dataset,\n",
    "          epochs=epochs,\n",
    "          validation_data=(dataset_val), batch_size=batch_size, initial_epoch=0,\n",
    "          callbacks=[checkpoint, lr_decay, tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T13:55:05.526297Z",
     "start_time": "2020-12-28T13:55:05.494954Z"
    }
   },
   "outputs": [],
   "source": [
    "model_eval.load_weights(saved_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T13:55:06.543579Z",
     "start_time": "2020-12-28T13:55:05.685417Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred, X_gen  = model_eval.predict(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T13:55:06.749134Z",
     "start_time": "2020-12-28T13:55:06.608430Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('-'*30 + 'MNIST test set' + '-'*30)\n",
    "acc = np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0]\n",
    "print('Test acc:', acc)\n",
    "print(f\"Test error %: {(1 - acc)*100:.4f}\")\n",
    "\n",
    "# plot some test and generatedd images\n",
    "img = combine_images(np.concatenate([X_test[:50],X_gen[:50]])) * 25\n",
    "Image.fromarray(img.astype(np.uint8)).save(media_dir.joinpath(f'{name_model}.png'))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:18:58.006396Z",
     "start_time": "2020-12-28T12:18:58.003046Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotImages(images, preds, labels, img_n, classes):\n",
    "    \"\"\"\n",
    "    Take as input a batch from the generator and plt a number of images equal to img_n\n",
    "    Default columns equal to max_c. At least inputs of batch equal two\n",
    "    \"\"\"\n",
    "    max_c = 5\n",
    "    \n",
    "    if img_n <= max_c:\n",
    "        r = 1\n",
    "        c = img_n\n",
    "    else:\n",
    "        r = math.ceil(img_n/max_c)\n",
    "        c = max_c\n",
    "        \n",
    "    fig, axes = plt.subplots(r, c, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, pred, label, ax in zip(images, preds, labels, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.grid()\n",
    "#    _ = plt.suptitle(\"Batch images\", verticalalignment='top')\n",
    "        ax.set_title('Class: {} Pred: {}'.format(np.argmax(label), np.argmax(pred)), color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:19:00.300725Z",
     "start_time": "2020-12-28T12:18:58.131292Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"N misclassified images (10K): {np.sum(np.argmax(y_pred, 1) != np.argmax(y_test, 1))}\")\n",
    "\n",
    "indices = np.argmax(y_pred, 1) != np.argmax(y_test, 1)\n",
    "plotImages(X_test[indices],y_pred[indices], y_test[indices], X_test[indices].shape[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CapsNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
